{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da00b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3112/628868562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import Libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import dlib\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import  time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyautogui as pyg\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8729656f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3112/3467550836.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#is a flag that sets the window to be resizable. This allows the user to adjust the size of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#the window as needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWINDOW_NORMAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#cv2.resizeWindow() is a function in the OpenCV library that resizes a window. The first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# If cleanup is True then the new images and annotations will be appended to previous ones\n",
    "# If False then all previous images and annotations will be deleted.\n",
    "cleanup = True\n",
    " \n",
    "# cv2.namedWindow() is a function in the OpenCV library that creates a window for displaying images.\n",
    "#The first argument, 'frame', is the name of the window. The second argument, cv2.WINDOW_NORMAL, \n",
    "#is a flag that sets the window to be resizable. This allows the user to adjust the size of\n",
    "#the window as needed.\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    " \n",
    "#cv2.resizeWindow() is a function in the OpenCV library that resizes a window. The first\n",
    "#argument is the name of the window, in this case, 'frame'. The second and third arguments\n",
    "#are the width and height of the window, respectively.\n",
    "\n",
    "#cv2.moveWindow() is a function in the OpenCV library that moves a window to a specific location\n",
    "#on the screen. The first argument is the name of the window, in this case, 'frame'. The second\n",
    "#and third arguments are the x and y coordinates of the location on the screen where you want the \n",
    "#window to be moved. In this case, the window is moved to the top-left corner of the screen (0, 0).\n",
    "\n",
    "cv2.resizeWindow('frame', 1920,1080)\n",
    "cv2.moveWindow(\"frame\", 0,0)\n",
    " \n",
    "# This code creates a VideoCapture object using the built-in OpenCV library. The parameter \"0\" is \n",
    "#passed to the constructor, indicating that the default camera on the device should be used. \n",
    "#The second parameter, \"CAP_DSHOW\", tells OpenCV to use the DirectShow backend for capturing video, \n",
    "#rather than the default backend. This object can then be used to capture video frames from the\n",
    "#camera and perform various operations on them\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    " \n",
    "# Initalize sliding window's x1,y1\n",
    "x1 ,y1 = 0,0\n",
    " \n",
    "# These will be the width and height of the sliding window.\n",
    "window_width = 190#140  \n",
    "window_height = 190\n",
    " \n",
    "# We will save images after every 4 frames\n",
    "# This is done so we don't have lot's of duplicate images\n",
    "skip_frames = 3\n",
    "frame_gap = 0\n",
    " \n",
    "# This is the directory where our images will be stored\n",
    "# Make sure to change both names if you're saving a different Detector\n",
    "directory = 'train_images_h'\n",
    "box_file = 'boxes_h.txt'\n",
    " \n",
    "# If cleanup is True then delete all imaages and bounding_box annotations.\n",
    "if cleanup:\n",
    "     \n",
    "    # Delete the images directory if it exists\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "     \n",
    "    # Clear up all previous bounding boxes\n",
    "    open(box_file, 'w').close()\n",
    "     \n",
    "    # Initialize the counter to 0\n",
    "    counter = 0\n",
    "     \n",
    "elif os.path.exists(box_file):\n",
    " \n",
    "    # If cleanup is false then we must append the new boxes with the old\n",
    "    with open(box_file,'r') as text_file:\n",
    "        box_content = text_file.read()\n",
    "         \n",
    "    # Set the counter to the previous highest checkpoint\n",
    "    counter = int(box_content.split(':')[-2].split(',')[-1])\n",
    " \n",
    "# Open up this text file or create it if it does not exists\n",
    "fr = open(box_file, 'a')\n",
    " \n",
    "# Create our image directory if it does not exists.\n",
    "if not os.path.exists(directory):\n",
    "   os.mkdir(directory)\n",
    " \n",
    "# Initial wait before you start recording each row\n",
    "initial_wait = 0\n",
    "         \n",
    "# Start the loop for the sliding window\n",
    "while(True):\n",
    "     \n",
    "    # Start reading from camera\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "         \n",
    "    # Invert the image laterally to get the mirror reflection.\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "     \n",
    "    # Make a copy of the original frame\n",
    "    orig = frame.copy()    \n",
    "     \n",
    "    # Wait the first 50 frames so that you can place your hand correctly\n",
    "    if initial_wait > 60:\n",
    "         \n",
    "        # Increment frame_gap by 1.\n",
    "        frame_gap +=1 \n",
    "     \n",
    "        # Move the window to the right by some amount in each iteration.    \n",
    "        if x1 + window_width < frame.shape[1]:\n",
    "            x1 += 4\n",
    "            time.sleep(0.1)            \n",
    "             \n",
    "        elif y1 + window_height + 270 < frame.shape[1]:\n",
    " \n",
    "            # If the sliding_window has reached the end of the row then move down by some amount.\n",
    "            # Also start the window from start of the row\n",
    "            y1 += 80   \n",
    "            x1 = 0\n",
    " \n",
    "            # Setting frame_gap and init_wait to 0.\n",
    "            # This is done so that the user has the time to place the hand correctly\n",
    "            # in the next row before image is saved.\n",
    "            frame_gap = 0\n",
    "            initial_wait = 0\n",
    "             \n",
    "        # Break the loop if we have gone over the whole screen.\n",
    "        else:\n",
    "            break\n",
    "               \n",
    "    else: \n",
    "        initial_wait += 1\n",
    " \n",
    "    # Save the image every nth frame.\n",
    "    if frame_gap == skip_frames:\n",
    " \n",
    "        # Set the image name equal to the counter value\n",
    "        img_name = str(counter)  + '.png'\n",
    " \n",
    "        # Save the Image in the defined directory\n",
    "        img_full_name = directory + '/' + str(counter) +  '.png'\n",
    "        cv2.imwrite(img_full_name, orig)\n",
    "         \n",
    "        # Save the bounding box coordinates in the text file.\n",
    "        fr.write('{}:({},{},{},{}),'.format(counter, x1, y1, x1+window_width, y1+window_height))\n",
    " \n",
    "        # Increment the counter \n",
    "        counter += 1\n",
    " \n",
    "        # Set the frame_gap back to 0.\n",
    "        frame_gap = 0\n",
    " \n",
    "    # Draw the sliding window\n",
    "    cv2.rectangle(frame,(x1,y1),(x1+window_width,y1+window_height),(0,255,0),3)\n",
    "     \n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    " \n",
    "# Release camera and close the file and window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    " \n",
    "# Get the indexes of all images.\n",
    "image_indexes = [int(img_name.split('.')[0]) for img_name in os.listdir(directory)]\n",
    " \n",
    "# Shuffle the indexes to have random train/test split later on.\n",
    "np.random.shuffle(image_indexes)\n",
    " \n",
    "# Open and read the content of the boxes.txt file\n",
    "f = open(box_file, \"r\")\n",
    "box_content = f.read()\n",
    " \n",
    "# Convert the bounding boxes to dictionary in the format `index: (x1,y1,x2,y2)` ...\n",
    "box_dict =  eval( '{' +box_content + '}' )\n",
    " \n",
    "# Close the file\n",
    "f.close()\n",
    " \n",
    "# Loop over all indexes\n",
    "for index in image_indexes:\n",
    "     \n",
    "    # Read the image in memmory and append it to the list\n",
    "    img = cv2.imread(os.path.join(directory, str(index) + '.png'))    \n",
    "     \n",
    "    # Read the associated bounding_box\n",
    "    bounding_box = box_dict[index]\n",
    "     \n",
    "    # Convert the bounding box to dlib format\n",
    "    x1, y1, x2, y2  = bounding_box\n",
    "    dlib_box = [ dlib.rectangle(left=x1 , top=y1, right=x2, bottom=y2) ]\n",
    "     \n",
    "    # Store the image and the box together\n",
    "    data[index] = (img, dlib_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65981fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_samples = 10\n",
    " \n",
    "image_names = os.listdir(directory)\n",
    " \n",
    "np.random.shuffle(data)\n",
    " \n",
    "# Extract the subset of boxes\n",
    "#subset = data[][:no_of_samples ]\n",
    " \n",
    "cols = 5\n",
    " \n",
    "# Given the number of samples to display, what's the number of rows required.\n",
    "rows = int(np.ceil(no_of_samples / cols))\n",
    " \n",
    "# Set the figure size\n",
    "plt.figure(figsize=(cols*cols, rows*cols))\n",
    " \n",
    "#Loop for each class\n",
    "for i in range(no_of_samples):\n",
    "         \n",
    "        # Extract the bonding box coordinates\n",
    "        d_box = data[i][1][0]\n",
    "        left, top, right,bottom = d_box.left(), d_box.top(), d_box.right(), d_box.bottom()\n",
    "         \n",
    "        # Get the image\n",
    "        image = data[i][0]\n",
    "         \n",
    "        # Draw reectangle on the detected hand\n",
    "        cv2.rectangle(image,(left,top),(right,bottom),(0,255,0),3)\n",
    "         \n",
    "        # Display the image\n",
    "        plt.subplot(rows,cols,i+1);plt.imshow(image[:,:,::-1]);plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487489c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This is the percentage of data we will use to train\n",
    "# The rest will be used for testing\n",
    "percent = 0.8\n",
    " \n",
    "# How many examples make 80%.\n",
    "split = int(len(data) * percent)\n",
    " \n",
    "# Seperate the images and bounding boxes in different lists.\n",
    "images = [tuple_value[0] for tuple_value in data.values()]\n",
    "bounding_boxes = [tuple_value[1] for tuple_value in data.values()]\n",
    " \n",
    "# Initialize object detector Options\n",
    "options = dlib.simple_object_detector_training_options()\n",
    " \n",
    "# I'm disabling the horizontal flipping, becauase it confuses the detector if you're training on few examples\n",
    "# By doing this the detector will only detect left or right hand (whichever you trained on). \n",
    "options.add_left_right_image_flips = False\n",
    " \n",
    "# Set the c parameter of SVM equal to 5\n",
    "# A bigger C encourages the model to better fit the training data, it can lead to overfitting.\n",
    "# So set an optimal C value via trail and error.\n",
    "options.C = 5\n",
    " \n",
    "# Note the start time before training.\n",
    "st = time.time()\n",
    " \n",
    "# You can start the training now\n",
    "detector = dlib.train_simple_object_detector(images[:split], bounding_boxes[:split], options)\n",
    " \n",
    "# Print the Total time taken to train the detector\n",
    "print('Training Completed, Total Time taken: {:.2f} seconds'.format(time.time() - st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'Head_Detector.svm'\n",
    "detector.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5487e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_det = dlib.image_window()\n",
    "win_det.set_image(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e9a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Metrics: {}\".format(dlib.test_simple_object_detector(images[:split], bounding_boxes[:split], detector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Metrics: {}\".format(dlib.test_simple_object_detector(images[split:], bounding_boxes[split:], detector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.train_simple_object_detector(images, bounding_boxes, options)\n",
    "detector.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a916a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = 'Hand_Detector.svm'\n",
    " \n",
    "# Load our trained detector \n",
    "detector = dlib.simple_object_detector(file_name)\n",
    " \n",
    "# Set the window name\n",
    "cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    " \n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    " \n",
    "# Setting the downscaling size, for faster detection\n",
    "# If you're not getting any detections then you can set this to 1\n",
    "scale_factor = 2.0\n",
    " \n",
    "# Initially the size of the hand and its center x point will be 0\n",
    "size, center_x = 0,0\n",
    " \n",
    "# Initialize these variables for calculating FPS\n",
    "fps = 0\n",
    "frame_counter = 0\n",
    "start_time = time.time()\n",
    " \n",
    "# Set the while loop\n",
    "while(True):\n",
    "     \n",
    "    # Read frame by frame\n",
    "    ret, frame = cap.read()\n",
    "     \n",
    "    if not ret:\n",
    "        break\n",
    "     \n",
    "    # Laterally flip the frame\n",
    "    frame = cv2.flip( frame, 1 )\n",
    "     \n",
    "    # Calculate the Average FPS\n",
    "    frame_counter += 1\n",
    "    fps = (frame_counter / (time.time() - start_time))\n",
    "     \n",
    "    # Create a clean copy of the frame\n",
    "    copy = frame.copy()  \n",
    "     \n",
    "    # Downsize the frame.\n",
    "    new_width = int(frame.shape[1]/scale_factor)\n",
    "    new_height = int(frame.shape[0]/scale_factor)\n",
    "    resized_frame = cv2.resize(copy, (new_width, new_height))\n",
    "     \n",
    "    # Detect with detector\n",
    "    detections = detector(resized_frame)\n",
    "     \n",
    "    # Loop for each detection.\n",
    "    for detection in (detections):    \n",
    "         \n",
    "        # Since we downscaled the image we will need to resacle the coordinates according to the original image.\n",
    "        x1 = int(detection.left() * scale_factor )\n",
    "        y1 =  int(detection.top() * scale_factor )\n",
    "        x2 =  int(detection.right() * scale_factor )\n",
    "        y2 =  int(detection.bottom()* scale_factor )\n",
    "         \n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0), 2 )\n",
    "        cv2.putText(frame, 'Hand Detected', (x1, y2+20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255),2)\n",
    " \n",
    "        # Calculate size of the hand. \n",
    "        size = int( (x2 - x1) * (y2-y1) )\n",
    "         \n",
    "        # Extract the center of the hand on x-axis.\n",
    "        center_x = x2 - x1 // 2\n",
    "     \n",
    "    # Display FPS and size of hand\n",
    "    cv2.putText(frame, 'FPS: {:.2f}'.format(fps), (20, 20), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255),2)\n",
    " \n",
    "    # This information is useful for when you'll be building hand gesture applications\n",
    "    cv2.putText(frame, 'Center: {}'.format(center_x), (540, 20), cv2.FONT_HERSHEY_COMPLEX, 0.5, (233, 100, 25))\n",
    "    cv2.putText(frame, 'size: {}'.format(size), (540, 40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (233, 100, 25))\n",
    "     \n",
    "    # Display the image\n",
    "    cv2.imshow('frame',frame)\n",
    "                   \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# Relase the webcam and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
